{"cells": [{"cell_type": "markdown", "metadata": {"id": "XCWncnhDcWYx"}, "source": ["# LAB 2 :: Python"]}, {"cell_type": "markdown", "metadata": {"id": "xRAx80PyeJGj"}, "source": ["## Get familier with Colab Notebook"]}, {"cell_type": "markdown", "metadata": {"id": "arF-QOPoe9sG"}, "source": ["February 22, 2024"]}, {"cell_type": "markdown", "metadata": {"id": "BtK90krefVUv"}, "source": ["Learning outcome:\n", "\n", "1.   Get familiar with Colab interactive python Notebook\n", "2.   Try some small exercises on the pre-work of data analysis, such as data loading, exploratory data analysis, visualization, etc.\n", "\n"]}, {"cell_type": "markdown", "metadata": {"id": "nasf-dKy_HPB"}, "source": ["**Lets import libraries**"]}, {"cell_type": "markdown", "metadata": {"id": "vkXfE3osgeGS"}, "source": ["**1 Load the housing dataset using pandas**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "1voGls__g6n_"}, "outputs": [], "source": ["import pandas as pd\n", "import os\n", "import tarfile"]}, {"cell_type": "markdown", "metadata": {"id": "NV-e9u9Jgve4"}, "source": ["*1.1 Download housing.tgz from LMS and save it in either local directory or google drive directory*"]}, {"cell_type": "markdown", "metadata": {"id": "svrYNRTPBVDl"}, "source": ["*Note: You can also upload into colab content directory*"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 73}, "id": "-DAcqhsQk5z6", "outputId": "62c41817-6a46-44dd-aca3-ee4d70296831"}, "outputs": [], "source": ["from google.colab import files\n", "uploaded = files.upload()"]}, {"cell_type": "markdown", "metadata": {"id": "C8HS-8yWC4nT"}, "source": ["Go to *Files -> contents* to see the uploaded files and sample datasets"]}, {"cell_type": "markdown", "metadata": {"id": "yEWL7NwlojQ8"}, "source": ["*1.2 Mount to the Drive*"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "HfayAblVl6mM", "outputId": "b0558dd0-fe36-4d17-9bf5-12d45c87cf3c"}, "outputs": [], "source": ["from google.colab import drive\n", "drive.mount('/mntDrive')"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "tDt5SGW9IlOk"}, "outputs": [], "source": ["# copy file into drive (optional-if needed)\n", "!cp housing.tgz /mntDrive/MyDrive/ColabNotebooks"]}, {"cell_type": "markdown", "metadata": {"id": "od3X44bvoycb"}, "source": ["*1.3 Extract tar*"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "T58IdKnyhEeI"}, "outputs": [], "source": ["notebooks = \"/mntDrive/MyDrive/ColabNotebooks\"\n", "tgz_path = os.path.join(notebooks,\"housing.tgz\")\n", "housing_tgz = tarfile.open(tgz_path)\n", "housing_tgz.extractall(path=os.path.join(notebooks,\"Data\"))\n", "housing_tgz.close()"]}, {"cell_type": "markdown", "metadata": {"id": "Sbehf66nhVfl"}, "source": ["*1.4 Write a small function to load the data:*"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "gZI53OethSbe"}, "outputs": [], "source": ["def load_housing_data(housing_path=None):\n", "  csv_path = os.path.join(notebooks, \"Data\", \"housing.csv\")\n", "  return pd.read_csv(csv_path)"]}, {"cell_type": "markdown", "metadata": {"id": "_wk0bn9xhZg6"}, "source": ["**Do ::** Check the top five rows using the head() method. <br>\n", "**Think ::** Pay attention to the attributes of a new dataset. <br>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 226}, "id": "byGbhqJbhn3v", "outputId": "8895c05b-778d-46b1-bffd-84538aab7c08"}, "outputs": [], "source": ["housing = load_housing_data()\n", "housing.head()"]}, {"cell_type": "markdown", "metadata": {"id": "J9MmkI29q0K2"}, "source": ["**Find ::** How many attributes? What are they?"]}, {"cell_type": "markdown", "metadata": {"id": "dlIZ2DrWrAh4"}, "source": ["Each row represents one district. <br> There are 10 attributes: longitude, latitude,housing_median_age,total_rooms, total_bed rooms, population, households, median_income, median_house_value, and ocean_proximit. <br> Later we will treate *median_house_value* as the output."]}, {"cell_type": "markdown", "metadata": {"id": "fVYuG8NbdfLv"}, "source": ["1.5 Alternatively, you can use info() method to get a quick description of the data.\n", "What is each attribute's data type?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "_KV5IGX8d09N", "outputId": "75576bad-34f3-4d52-a764-2fcc2c28617a"}, "outputs": [], "source": ["housing.info()"]}, {"cell_type": "markdown", "metadata": {"id": "6c2kgjDmenIN"}, "source": ["All attributes are numerical, except the ocean_proximity field (type is object), so it could hold any kind of Python object, from the CSV file we know that it must be a text attribute.\n", "<br>\n"]}, {"cell_type": "markdown", "metadata": {"id": "MAfV82vxGfep"}, "source": ["**1.6 Do: Find out what categories exist in `ocean_proximity', and how many districts belong to each category using *value_count()* method.**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "KCEkJFiIe9tF", "outputId": "014d66f7-f1d1-45c4-d21e-9d76a1ccb240"}, "outputs": [], "source": ["housing[\"ocean_proximity\"].value_counts()"]}, {"cell_type": "markdown", "metadata": {"id": "Y2QKfbb6fNgb"}, "source": ["1.7 Next, describe() method shows a summary of the numerical attributes."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 320}, "id": "nmHP3BnvfUut", "outputId": "f14a9f3b-1a1c-4d65-d5eb-43e1a6a9c50a"}, "outputs": [], "source": ["housing.describe()"]}, {"cell_type": "markdown", "metadata": {"id": "QaEfhOEefx9i"}, "source": ["**Query:** What doi you observe?"]}, {"cell_type": "markdown", "metadata": {"id": "Wx-OM8NBf3VS"}, "source": ["total_bedrooms -> 20,433, not 20,640.\n", "This is because the null values are ignored."]}, {"cell_type": "markdown", "metadata": {"id": "_NzY2q5cf8-5"}, "source": ["Anything else?"]}, {"cell_type": "markdown", "metadata": {"id": "sRH7IYexgDix"}, "source": ["Let's plot a histogram for each numerical attribute to get a feel of the data we are dealing with. <br> A\n", "histogram shows the number of instances (on the vertical axis) that have a given value range (on the horizontal axis)."]}, {"cell_type": "markdown", "metadata": {"id": "ri-xE1SLgL9R"}, "source": ["Before we can plot anything, we need to specify which backend Matplotlib should use.\n", "We will use Jupyter's magic command %matplotlib inline -> This tells Jupyter to set up Matplotlib,\n", "so it uses Jupyter's own backend. Plots are then rendered within the notebook itself."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "SAD5DT9_geq5"}, "outputs": [], "source": ["%matplotlib inline\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 490}, "id": "7ivrpoZFgjEU", "outputId": "bda6b318-0fc4-488f-c6c1-4238bed3c8ce"}, "outputs": [], "source": ["housing.hist(bins=50, figsize=(20,15))\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"id": "oXygAkwggrVJ"}, "source": ["Query: Do you observe any problems with these histograms?\n", "1. These attributes have very different scales.\n", "<br>\n", "2. Many histograms are tail heavy: they extend much\n", "farther to the right of the median than to the left. This may make it a bit harder for some Machine Learning algorithms to detect patterns. We will need to transform these attributes later on to have more bell-shaped distributions.\n", "<br>\n", "3. Median house value were capped. It may be a serious problem\n", "since it is your target attribute (your labels). Your Machine Learning algorithms may learn that prices never go beyond that limit. Possible options: a. Collect proper labels for the districts whose\n", "labels were capped. b. Remove those districts from the training set and the test set."]}, {"cell_type": "markdown", "metadata": {"id": "zecoxxj5kU7W"}, "source": ["**2 Create a Test Set**"]}, {"cell_type": "markdown", "metadata": {"id": "DjjWWd6jkdRM"}, "source": ["The idea of creating a test set is simple: pick some instances randomly,typically 20% of the dataset (the ratio may vary), and set them aside."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "13eeJO70kiAs"}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "H6izpapJki4Y"}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split"]}, {"cell_type": "markdown", "metadata": {"id": "ISdRBSu4knTO"}, "source": ["*2.1 Random sampling*"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "cTsPHKbjkmfv"}, "outputs": [], "source": ["train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"]}, {"cell_type": "markdown", "metadata": {"id": "r10-Qa_JnTcr"}, "source": ["**Query:** Can you create five random sets of separate train and test splits? <br>\n", "**Do:** Create a list/set containing both five of train_sets and test_sets"]}, {"cell_type": "markdown", "metadata": {"id": "VDP4ABRglDJP"}, "source": ["*2.2 Stratifed sampling*"]}, {"cell_type": "markdown", "metadata": {"id": "zvPV08tIlDIF"}, "source": ["We're told that the median income is essential in predicting median housing prices. So we want to ensure that the test set is representative of the various categories of incomes in the whole dataset."]}, {"cell_type": "markdown", "metadata": {"id": "ZtmFcN9-lXbm"}, "source": ["The following code uses the *pd.cut()* function to create an income category attribute with five\n", "categories:\n", "<br>\n", "category 1 0-1.5\n", "<br>\n", "category 2 1.3-3,\n", "<br>\n", "and so on"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "MD3igevyl0ap"}, "outputs": [], "source": ["housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n", "bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n", "labels=[1,2,3,4,5])"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 448}, "id": "OlFrFawwmJ4G", "outputId": "4f21afbe-fe86-45d5-f86d-b6e72c4e0142"}, "outputs": [], "source": ["housing[\"income_cat\"].hist()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "mXEyzBkdmWRW"}, "outputs": [], "source": ["from sklearn.model_selection import StratifiedShuffleSplit"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "o8kgnOS5mXYO"}, "outputs": [], "source": ["split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n", "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n", "  strat_train_set = housing.loc[train_index]\n", "  strat_test_set = housing.loc[test_index]"]}, {"cell_type": "markdown", "metadata": {"id": "csjcyJJfmgU4"}, "source": ["Check the income category proportions in the test set"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "EqZiLzJPmiX2", "outputId": "4312c5ff-2c14-4d92-b6d4-45663659d0da"}, "outputs": [], "source": ["strat_test_set[\"income_cat\"].value_counts()/len(strat_test_set)"]}, {"cell_type": "markdown", "metadata": {"id": "U_0jrchDm2Zm"}, "source": ["Now we need to delete the `income_cat' attribute, so the data is back to its original state."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "4KleYLI-m3jO"}, "outputs": [], "source": ["for set_ in (strat_train_set, strat_test_set):\n", "  set_.drop(\"income_cat\", axis=1, inplace=True)"]}, {"cell_type": "markdown", "metadata": {"id": "dprXYk5goDcu"}, "source": ["# 3 Discover the dataset - visualization\n", "Next we will only explore the trainig data set and put the testing set aside. Let's create a copy so\n", "that the following procedures will not harm the training"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "HckPtZfKoKp2"}, "outputs": [], "source": ["housing = strat_train_set.copy()"]}, {"cell_type": "markdown", "metadata": {"id": "n-CkEGGaoNHe"}, "source": ["Do: Let's first create a scatterplot of all districts to visualize the data."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 467}, "id": "aKIWSTfgoiv2", "outputId": "3bee74ff-cd0d-497e-de75-aeb38d5b5ef2"}, "outputs": [], "source": ["housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"]}, {"cell_type": "markdown", "metadata": {"id": "71V-ClPLodRe"}, "source": ["We can observe an overplotting issue, making it difficult to see individual data points in a data visualization"]}, {"cell_type": "markdown", "metadata": {"id": "Du_mrU2Jorg-"}, "source": ["We can adjust the alpha option to make the visualization better refect the high density of data\n", "points."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 467}, "id": "wz-klfzLovTG", "outputId": "a841ada8-f65d-4986-f9b5-d529cbfde2ac"}, "outputs": [], "source": ["housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"]}, {"cell_type": "markdown", "metadata": {"id": "v_-DwUGTqs6b"}, "source": ["Query: Can you visualise the lattitude and longitude relationship using other kind of plot? <br>\n", "Go thorugh https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.plot.html\n", "*   Identify and observe the changes\n", "*   Comment on the intuitive plot (s)\n", "\n"]}, {"cell_type": "markdown", "metadata": {"id": "yiphLBbxo4df"}, "source": ["# 4 Correlations between attributes\n", "We can easily compute the standard correlation coeffcient between every pair of attributes\n", "For example, let's check how much each attribute correlates with the median house value:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "hjSa3z13pBAn", "outputId": "75d34347-574e-4667-c307-1b5de399c3d2"}, "outputs": [], "source": ["corr_matrix = housing.corr()\n", "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"]}, {"cell_type": "markdown", "metadata": {"id": "5X80H1ZzpLS_"}, "source": ["How to interpret the results? <br>\n", "The correlation coffcient ranges from -1 to 1. When it is close to 1, it means that there is a strong positive correlation;  <br>\n", "for example, the median house value tends to go up when the median income\n", "goes up.\n", "<br>\n", "When the coeffcient is close to -1, it means that there is a strong negative correlation; <br>\n", "You can see a small negative correlation between the latitude and the median house value (i.e., prices have a slight tendency to go down when you go north). Finally, coefficients close to zero mean that there is no linear correlation."]}, {"cell_type": "markdown", "metadata": {"id": "USl-W48QpuXS"}, "source": ["Alternatively, we can check for correlations between attributes using the pandas *scatter_matrix()* function. <br>\n", "Let's focus on a few promising attributes that seem most correlated with the median housing value."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "Pq7_dMbHpSJt"}, "outputs": [], "source": ["from pandas.plotting import scatter_matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 760}, "id": "8VEgxt1Cp64h", "outputId": "ed1daa26-bbcd-4908-8b21-a5c0a60d8971"}, "outputs": [], "source": ["attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\"housing_median_age\"]\n", "scatter_matrix(housing[attributes], figsize=(12, 8))"]}, {"cell_type": "markdown", "metadata": {"id": "dq6wchF0p2Qy"}, "source": ["Which attributes seem to be more predictable of the median house value?\n", "<br>\n"]}, {"cell_type": "markdown", "metadata": {"id": "3XXqCTEqrHv5"}, "source": ["*First,* correlation between the median house value and median income is indeed very strong;\n", "you can clearly see the upward trend and the points are not too dispersed. <br>\n", "*Second*, the price cap that\n", "we noticed earlier is clearly visible as a horizontal line at 500,000. But this plot reveals other less obvious straight lines: a horizontal line around 450,000, another around 350,000, perhaps one around 280,000, and a few more below that. You may want to try removing the corresponding\n", "districts to prevent your algorithms from learning to reproduce these data quirks. <br>"]}, {"cell_type": "markdown", "metadata": {"id": "oSRWHSmQsKMx"}, "source": ["Query: Can you visulase the correlation between variables. <br>\n", "Do:Go thrugh the documentation about python packages: heatmapz/ seaborn"]}, {"cell_type": "markdown", "metadata": {"id": "06-5pVgxIAqV"}, "source": ["# **Discuss in groups and answer the following questions:**:\n", "1. Can you estimate the median house value from a set of variable inputs (except median house value)?\n", "2. Is it a machine learning problem?\n", "3. What sort of machine learning problem it is?\n", "4. Which important variables are statistically contributing for the house value?\n", "5. advance: Can you form the group of districts based on their attribute/feature/variable (in this context) values?\n", "\n", "*Note: Support your answer with any sort of logical reasoning.*"]}, {"cell_type": "markdown", "metadata": {"id": "GG5OGqo-rTm_"}, "source": ["** Disclaimer: The above code is modifed from the textbook \"Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow\"."]}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.4"}}, "nbformat": 4, "nbformat_minor": 1}
