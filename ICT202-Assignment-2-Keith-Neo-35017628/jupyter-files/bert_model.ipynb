{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Model Training \n", "This section will train the BERT model with the cleaned dataset.\n", "\n", "### Import required Library"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Download sentence transformer and encoder for BERT"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Importing all required libraries\n", "from bertopic import BERTopic\n", "import pandas as pd \n", "import os\n", "import pickle"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Import the cleaned dataset for BERT"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["DATADIR = f\"{os.path.abspath(os.path.join(os.getcwd(), os.pardir))}/dataset\"\n", "cleaned_df = pd.read_csv(f\"{DATADIR}/cleaned_tweets.csv\")\n", "\n", "cleaned_df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Train the BERT model\n", "This section will train the bert model if it does not exist. If not it will import the exisiting model to save time. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MODELDIR = f\"{os.path.abspath(os.path.join(os.getcwd(), os.pardir))}/model\"\n", "model_path = f\"{MODELDIR}/bert\"\n", "\n", "def train_model():\n", "    if not os.path.exists(MODELDIR):\n", "        os.makedirs(MODELDIR)\n", "    bert_model = BERTopic(verbose=True)\n", "    tweets = cleaned_df['cleaned_tweet'].to_list()\n", "    topics, probabilities = bert_model.fit_transform(tweets)\n", "    bert_model.save(f\"{MODELDIR}/bert\", serialization=\"pickle\")\n", "    # save_model(bert_model, \"bert\")\n", "\n", "if os.path.isfile(model_path):\n", "    bert_model = BERTopic.load(model_path)\n", "else: \n", "    train_model()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Interpretation of Results \n", "\n", "### Topic Information\n", "The `get_topic_info` method provides an overview of the topics identified by the model, inclluding their size"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bert_model.get_topic_info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Top Words in Each Topic\n", "The `get_topic` method returns the top words for a specific topic. This can help in understanding the main themes of each topic."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bert_model.get_topic(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Topic Frequency\n", "The `get_topic_freq` method shows the frequency of each topic, which helps in identifying the most dominant topics."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Show the size of topics in descending order\n", "bert_model.get_topic_freq()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Visualisation for BERT model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bert_model.visualize_topics()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualise Terms \n", "This method will show a few selected terms in bar chart format of the TF-IDF scores."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bert_model.visualize_barchart()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualise Topic Similarity \n", "This method will visualise how similar certain topics are to each other using a heatmap."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bert_model.visualize_heatmap()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualise Topics Hierarchy\n", "This method will visualize the topics hierarchy."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bert_model.visualize_hierarchy()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualise Topic Word Cloud \n", "Word clouds can provide an intuitive way to understand the most frequent words in each topic"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from wordcloud import WordCloud\n", "import matplotlib.pyplot as plt\n", "\n", "def create_wordcloud(model, topic):\n", "    text = {word: value for word, value in model.get_topic(topic)}\n", "    wc = WordCloud().generate_from_frequencies(text)\n", "    plt.imshow(wc, interpolation='bilinear')\n", "    plt.axis(\"off\")\n", "    plt.show()\n", "\n", "# Show word cloud\n", "create_wordcloud(bert_model, 0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Unsupervised Topic Modeling Evaluation "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Import necessary packages\n", "\n", "`gensim` will be used for Coherence & `scikit-learn` will be used for Silhouette Score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from gensim.corpora import Dictionary\n", "from gensim.models import CoherenceModel"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Prepare the tweets \n", "tweets = cleaned_df['cleaned_tweet'].to_list()\n", "texts = [tweet.split() for tweet in tweets]\n", "\n", "# create a Gensim dictionary and corpus\n", "dictionary = Dictionary(texts)\n", "corpus = [dictionary.doc2bow(text) for text in texts]\n", "\n", "# get topic in the format required by Gensim\n", "topics = bert_model.get_topics()\n", "formatted_topics = [[word for word, _ in topic] for topic in topics.values()]\n", "\n", "# Calculate Coherence Score using Gensim\n", "coherence_model = CoherenceModel(topics=formatted_topics, texts=texts, dictionary=dictionary, coherence='c_v')\n", "coherence_score = coherence_model.get_coherence()\n", "\n", "f\"Coherence Score: {coherence_score}\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Silhouette Score with scikit-learn\n", "This will take some time depending on user system."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import silhouette_score\n", "from sklearn.utils import shuffle\n", "\n", "# shuffle and subsample the data \n", "subsample_size = 1000 \n", "cleaned_df_subsample = shuffle(cleaned_df).head(subsample_size)\n", "\n", "# get topic assignments and probabilities\n", "topics, probabilities = bert_model.fit_transform(cleaned_df_subsample['cleaned_tweet'])\n", "\n", "# convert the probabilities to a 2d array\n", "probabilities_2d = pd.DataFrame(probabilities).values\n", "\n", "# calculate Silhouette Score using topic probabilities \n", "sil_score = silhouette_score(probabilities_2d, topics)\n", "f\"Silhouette Score: {sil_score}\""]}], "metadata": {"kernelspec": {"display_name": "assess2", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.4"}}, "nbformat": 4, "nbformat_minor": 2}
